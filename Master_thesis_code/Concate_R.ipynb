{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "6\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "Epoch 1/4\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.6965 - accuracy: 0.5000 - val_loss: 0.6741 - val_accuracy: 0.5000\n",
      "Epoch 2/4\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6774 - accuracy: 0.5000 - val_loss: 0.6380 - val_accuracy: 1.0000\n",
      "Epoch 3/4\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6490 - accuracy: 0.8333 - val_loss: 0.5832 - val_accuracy: 0.5000\n",
      "Epoch 4/4\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6135 - accuracy: 0.5000 - val_loss: 0.5426 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25579e663c8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten, Input\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Add\n",
    "from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# First Thermal model training\n",
    "\n",
    "image_list = []\n",
    "\n",
    "def my_load_Train_data_1() :\n",
    "    image_list = []\n",
    "    for filename in glob.glob('C:/Users/MANDEEP SINGH SHERRY/Desktop/thermal train/*.jpg'): #assuming gif\n",
    "        im=Image.open(filename)\n",
    "        img = im.resize((32,32),Image.ANTIALIAS)\n",
    "        img= tf.keras.preprocessing.image.img_to_array(img)\n",
    "        img= img.reshape(32, 32, 3)\n",
    "        img =img.astype('float32')\n",
    "        img = img / 255.0\n",
    "        image_list.append(img)\n",
    "\n",
    "    return image_list\n",
    "\n",
    "def my_load_Test_data_1() :\n",
    "    image_list = []\n",
    "    for filename in glob.glob('C:/Users/MANDEEP SINGH SHERRY/Desktop/thermal test/*.jpg'): #assuming gif\n",
    "        im=Image.open(filename)\n",
    "        img = im.resize((32,32),Image.ANTIALIAS)\n",
    "        img= tf.keras.preprocessing.image.img_to_array(img)\n",
    "        img= img.reshape(32, 32, 3)\n",
    "        img =img.astype('float32')\n",
    "        img = img / 255.0\n",
    "        image_list.append(img)\n",
    "\n",
    "    return image_list\n",
    "\n",
    "X1_train = my_load_Train_data_1()\n",
    "X1_test = my_load_Test_data_1()\n",
    "print(len(X1_test))\n",
    "y1_train = pd.read_csv('C:/Users/MANDEEP SINGH SHERRY/Desktop/y_labels.csv')\n",
    "y1_test = [[1],\n",
    "           [1],\n",
    "           [1],\n",
    "           [0],\n",
    "           [0],\n",
    "           [0]]\n",
    "n_classes = 2\n",
    "X1_train = np.array(X1_train)\n",
    "Y1_train = np.array(y1_train)\n",
    "X1_test = np.array(X1_test)\n",
    "Y1_test = np.array(y1_test)\n",
    "\n",
    "Y1_train = np_utils.to_categorical(Y1_train, n_classes)\n",
    "Y1_test = np_utils.to_categorical(Y1_test, n_classes)\n",
    "len(X1_train)\n",
    "print(Y1_test)\n",
    "X1_train.shape\n",
    "\n",
    "#secound model training\n",
    "\n",
    "image_list = []\n",
    "\n",
    "def my_load_Train_data_2() :\n",
    "    image_list = []\n",
    "    for filename in glob.glob('C:/Users/MANDEEP SINGH SHERRY/Desktop/train/apple/*.jpg'): #assuming gif\n",
    "        im=Image.open(filename)\n",
    "        img = im.resize((32,32),Image.ANTIALIAS)\n",
    "        img= tf.keras.preprocessing.image.img_to_array(img)\n",
    "        img= img.reshape(32, 32, 3)\n",
    "        img =img.astype('float32')\n",
    "        img = img / 255.0\n",
    "        image_list.append(img)\n",
    "\n",
    "    return image_list\n",
    "\n",
    "def my_load_Test_data_2() :\n",
    "    image_list = []\n",
    "    for filename in glob.glob('C:/Users/MANDEEP SINGH SHERRY/Desktop/test/*.jpg'): #assuming gif\n",
    "        im=Image.open(filename)\n",
    "        img = im.resize((32,32),Image.ANTIALIAS)\n",
    "        img= tf.keras.preprocessing.image.img_to_array(img)\n",
    "        img= img.reshape(32, 32, 3)\n",
    "        img =img.astype('float32')\n",
    "        img = img / 255.0\n",
    "        image_list.append(img)\n",
    "\n",
    "    return image_list\n",
    "\n",
    "X2_train = my_load_Train_data_2()\n",
    "X2_test = my_load_Test_data_2()\n",
    "print(len(X2_test))\n",
    "y2_train = pd.read_csv('C:/Users/MANDEEP SINGH SHERRY/Desktop/y_labels.csv')\n",
    "y2_test = [[1],\n",
    "           [1],\n",
    "           [1],\n",
    "           [0],\n",
    "           [0],\n",
    "           [0]]\n",
    "n_classes = 2\n",
    "X2_train = np.array(X2_train)\n",
    "Y2_train = np.array(y2_train)\n",
    "X2_test = np.array(X2_test)\n",
    "Y2_test = np.array(y2_test)\n",
    "\n",
    "Y2_train = np_utils.to_categorical(Y2_train, n_classes)\n",
    "Y2_test = np_utils.to_categorical(Y2_test, n_classes)\n",
    "len(X2_train)\n",
    "print(Y2_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Model 1(Thermal)\n",
    "inp1 = Input(shape=(32, 32, 3))\n",
    "\n",
    "# convolutional layer\n",
    "conv1=Conv2D(100, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(inp1)\n",
    "\n",
    "# convolutional layer\n",
    "conv2 =Conv2D(75, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(conv1)\n",
    "pool1=MaxPool2D(pool_size=(2,2))(conv2)\n",
    "conv3=Conv2D(50, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(pool1)\n",
    "pool2=MaxPool2D(pool_size=(2,2))(conv3)\n",
    "\n",
    "# flatten output of conv\n",
    "flat1=Flatten()(pool2)\n",
    "\n",
    "# hidden layer\n",
    "hidd1=(Dense(25, activation='relu'))(flat1)\n",
    "dense1=(Dense(10, activation='relu'))(hidd1)\n",
    "output1=Flatten()(dense1)\n",
    "#output= (Dense(10, activation='relu'))(model_1)\n",
    "\n",
    "# Model 2\n",
    "\n",
    "\n",
    "\n",
    "# convolutional layer\n",
    "inp2 = Input(shape=(32, 32, 3))\n",
    "\n",
    "# convolutional layer\n",
    "conv1 =Conv2D(100, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(inp2)\n",
    "\n",
    "# convolutional layer\n",
    "conv2 =Conv2D(75, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(conv1)\n",
    "pool1=MaxPool2D(pool_size=(2,2))(conv2)\n",
    "conv3=Conv2D(50, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(pool1)\n",
    "pool2=MaxPool2D(pool_size=(2,2))(conv3)\n",
    "\n",
    "# flatten output of conv\n",
    "flat1=Flatten()(pool2)\n",
    "\n",
    "# hidden layer\n",
    "hidd1=Dense(25, activation='relu')(flat1)\n",
    "dense2=Dense(10, activation='relu')(hidd1)\n",
    "output2=Flatten()(dense2)\n",
    "# concatinate two models \n",
    "\n",
    "\n",
    "concat1 = concatenate([output1, output2])\n",
    "Out  = Dense(2, activation='softmax')(concat1)\n",
    "\n",
    "model = Model(inputs=[inp1, inp2], outputs = Out)\n",
    "\n",
    "# compiling the sequential model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') \n",
    "\n",
    "\n",
    "## output layer\n",
    "#model_1.add(Dense(2, activation='softmax'))\n",
    "\n",
    "## compiling the sequential model\n",
    "#model_1.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "# training the model for 10 epochs\n",
    "model.fit([X1_train,X2_train],Y2_train, batch_size=128,epochs=4,validation_data=([X1_test,X2_test],Y2_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\MANDEEP SINGH SHERRY\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\MANDEEP SINGH SHERRY\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: concatModel\\assets\n",
      "[[0.44292095 0.557079  ]]\n"
     ]
    }
   ],
   "source": [
    "model.save(\"concatModel\")\n",
    "# make a prediction for a new image.\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "# load the image thermal\n",
    "img1 = load_img('a4.jpg', target_size=(32, 32))\n",
    "# convert to array\n",
    "img1 = img_to_array(img1)\n",
    "# reshape into a single sample with 3 channels\n",
    "img1 = img1.reshape(1,32, 32, 3)\n",
    "# prepare pixel data\n",
    "img1 = img1.astype('float32')\n",
    "img1 = img1 / 255.0\n",
    "# for second\n",
    "img2 = load_img('apple4.jpg', target_size=(32, 32))\n",
    "# convert to array\n",
    "img2 = img_to_array(img2)\n",
    "# reshape into a single sample with 3 channels\n",
    "img2 = img2.reshape(1,32, 32, 3)\n",
    "# prepare pixel data\n",
    "img2 = img2.astype('float32')\n",
    "img2 = img2 / 255.0\n",
    "result = model.predict([img1,img2])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probality of Banana\n",
      "0.44292095\n",
      "probality of Apple\n",
      "0.557079\n"
     ]
    }
   ],
   "source": [
    "print(\"probality of Banana\")\n",
    "print(result[0][0])\n",
    "print(\"probality of Apple\")\n",
    "print(result[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-390b5ec9290d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloaded_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"concatModel\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimg1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "loaded_model = keras.models.load_model(\"concatModel\")\n",
    "result = loaded_model.predict([img1,img2])\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
