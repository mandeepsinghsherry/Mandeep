{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "6\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-5e54b38b7610>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[0mmodel_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;31m#model_1.add(Dense(10, activation='relu'))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;31m# Model 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    980\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 982\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2616\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2617\u001b[0m       input_spec.assert_input_compatibility(\n\u001b[1;32m-> 2618\u001b[1;33m           self.input_spec, inputs, self.name)\n\u001b[0m\u001b[0;32m   2619\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2620\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dtype_policy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_dtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_ndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         spec.max_ndim is not None):\n\u001b[1;32m--> 166\u001b[1;33m       \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\u001b[0;32m    168\u001b[0m                          \u001b[0mlayer_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' is incompatible with the layer: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Add\n",
    "from keras.layers import concatenate\n",
    "\n",
    "\n",
    "# First model training\n",
    "\n",
    "image_list = []\n",
    "\n",
    "def my_load_Train_data_1() :\n",
    "    image_list = []\n",
    "    for filename in glob.glob('C:/Users/MANDEEP SINGH SHERRY/Desktop/thermal train/*.jpg'): #assuming gif\n",
    "        im=Image.open(filename)\n",
    "        img = im.resize((32,32),Image.ANTIALIAS)\n",
    "        img= tf.keras.preprocessing.image.img_to_array(img)\n",
    "        img= img.reshape(32, 32, 3)\n",
    "        img =img.astype('float32')\n",
    "        img = img / 255.0\n",
    "        image_list.append(img)\n",
    "\n",
    "    return image_list\n",
    "\n",
    "def my_load_Test_data_1() :\n",
    "    image_list = []\n",
    "    for filename in glob.glob('C:/Users/MANDEEP SINGH SHERRY/Desktop/thermal test/*.jpg'): #assuming gif\n",
    "        im=Image.open(filename)\n",
    "        img = im.resize((32,32),Image.ANTIALIAS)\n",
    "        img= tf.keras.preprocessing.image.img_to_array(img)\n",
    "        img= img.reshape(32, 32, 3)\n",
    "        img =img.astype('float32')\n",
    "        img = img / 255.0\n",
    "        image_list.append(img)\n",
    "\n",
    "    return image_list\n",
    "\n",
    "X1_train = my_load_Train_data_1()\n",
    "X1_test = my_load_Test_data_1()\n",
    "print(len(X1_test))\n",
    "y1_train = [[1],\n",
    "           [1],\n",
    "           [1],\n",
    "           [1],\n",
    "           [1],\n",
    "           [1],\n",
    "           [1],\n",
    "           [1],\n",
    "           [1],\n",
    "           [1],\n",
    "           [1],\n",
    "           [1],\n",
    "           [0],\n",
    "           [0],\n",
    "           [0],\n",
    "           [0],\n",
    "           [0],\n",
    "           [0],\n",
    "           [0],\n",
    "           [0],\n",
    "           [0],\n",
    "           [0],\n",
    "           [0],\n",
    "           [0]]\n",
    "y1_test = [[1],\n",
    "           [1],\n",
    "           [1],\n",
    "           [0],\n",
    "           [0],\n",
    "           [0]]\n",
    "n_classes = 2\n",
    "X1_train = np.array(X1_train)\n",
    "Y1_train = np.array(y1_train)\n",
    "X1_test = np.array(X1_test)\n",
    "Y1_test = np.array(y1_test)\n",
    "\n",
    "Y1_train = np_utils.to_categorical(Y1_train, n_classes)\n",
    "Y1_test = np_utils.to_categorical(Y1_test, n_classes)\n",
    "len(X1_train)\n",
    "print(Y1_test)\n",
    "X1_train.shape\n",
    "\n",
    "#secound model training\n",
    "\n",
    "image_list = []\n",
    "\n",
    "def my_load_Train_data_2() :\n",
    "    image_list = []\n",
    "    for filename in glob.glob('C:/Users/MANDEEP SINGH SHERRY/Desktop/train/apple/*.jpg'): #assuming gif\n",
    "        im=Image.open(filename)\n",
    "        img = im.resize((32,32),Image.ANTIALIAS)\n",
    "        img= tf.keras.preprocessing.image.img_to_array(img)\n",
    "        img= img.reshape(32, 32, 3)\n",
    "        img =img.astype('float32')\n",
    "        img = img / 255.0\n",
    "        image_list.append(img)\n",
    "\n",
    "    return image_list\n",
    "\n",
    "def my_load_Test_data_2() :\n",
    "    image_list = []\n",
    "    for filename in glob.glob('C:/Users/MANDEEP SINGH SHERRY/Desktop/test/*.jpg'): #assuming gif\n",
    "        im=Image.open(filename)\n",
    "        img = im.resize((32,32),Image.ANTIALIAS)\n",
    "        img= tf.keras.preprocessing.image.img_to_array(img)\n",
    "        img= img.reshape(32, 32, 3)\n",
    "        img =img.astype('float32')\n",
    "        img = img / 255.0\n",
    "        image_list.append(img)\n",
    "\n",
    "    return image_list\n",
    "\n",
    "X2_train = my_load_Train_data_2()\n",
    "X2_test = my_load_Test_data_2()\n",
    "print(len(X2_test))\n",
    "y2_train = [[1],\n",
    "           [1],\n",
    "           [1],\n",
    "           [1],\n",
    "           [1],\n",
    "           [1],\n",
    "           [0],\n",
    "           [0],\n",
    "           [0],\n",
    "           [0],\n",
    "           [0],\n",
    "           [0]]\n",
    "y2_test = [[0],\n",
    "           [1],\n",
    "           [1],\n",
    "           [1],\n",
    "           [0],\n",
    "           [0]]\n",
    "n_classes = 2\n",
    "X2_train = np.array(X2_train)\n",
    "Y2_train = np.array(y2_train)\n",
    "X2_test = np.array(X2_test)\n",
    "Y2_test = np.array(y2_test)\n",
    "\n",
    "Y2_train = np_utils.to_categorical(Y2_train, n_classes)\n",
    "Y2_test = np_utils.to_categorical(Y2_test, n_classes)\n",
    "len(X2_train)\n",
    "print(Y2_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Model 1\n",
    "\n",
    "model_1 = Sequential()\n",
    "\n",
    "# convolutional layer\n",
    "model_1.add(Conv2D(100, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
    "\n",
    "# convolutional layer\n",
    "model_1.add(Conv2D(75, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "model_1.add(MaxPool2D(pool_size=(2,2)))\n",
    "model_1.add(Dropout(0.10))\n",
    "\n",
    "model_1.add(Conv2D(50, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "model_1.add(MaxPool2D(pool_size=(2,2)))\n",
    "model_1.add(Dropout(0.10))\n",
    "\n",
    "\n",
    "\n",
    "# flatten output of conv\n",
    "model_1.add(Flatten())\n",
    "\n",
    "# hidden layer\n",
    "model_1.add(Dense(25, activation='relu'))\n",
    "model_1.add(Dropout(0.5))\n",
    "model_1.add(Dense(10, activation='relu'))\n",
    "#output= (Dense(10, activation='relu'))(model_1)\n",
    "\n",
    "# Model 2\n",
    "\n",
    "\n",
    "model_2 = Sequential()\n",
    "\n",
    "# convolutional layer\n",
    "model_2.add(Conv2D(100, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
    "\n",
    "# convolutional layer\n",
    "model_2.add(Conv2D(75, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "model_2.add(MaxPool2D(pool_size=(2,2)))\n",
    "model_2.add(Dropout(0.10))\n",
    "\n",
    "model_2.add(Conv2D(50, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "model_2.add(MaxPool2D(pool_size=(2,2)))\n",
    "model_2.add(Dropout(0.10))\n",
    "\n",
    "# flatten output of conv\n",
    "model_2.add(Flatten())\n",
    "\n",
    "# hidden layer\n",
    "model_2.add(Dense(25, activation='relu'))\n",
    "model_2.add(Dropout(0.5))\n",
    "model_2.add(Dense(10, activation='relu'))\n",
    "#output= (Dense(10, activation='relu'))(model_2)\n",
    "\n",
    "# concatinate two models \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Final Model\n",
    "\n",
    "final_model = Sequential()\n",
    "final_model.add(concatenate([model_1.output, model_2.output], axis= -1))\n",
    "final_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# compiling the sequential model\n",
    "final_model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='rmsprop') \n",
    "\n",
    "\n",
    "## output layer\n",
    "#model_1.add(Dense(2, activation='softmax'))\n",
    "\n",
    "## compiling the sequential model\n",
    "#model_1.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "# training the model for 10 epochs\n",
    "final_model.fit([X1_train,X2_train],Y1_train, Y2_train, batch_size=128,epochs=32,validation_data=(X1_test, Y1_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction for a new image.\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "\n",
    "# load the image\n",
    "img = load_img('a1.jpg', target_size=(32, 32))\n",
    "# convert to array\n",
    "img = img_to_array(img)\n",
    "# reshape into a single sample with 3 channels\n",
    "img = img.reshape(1,32, 32, 3)\n",
    "# prepare pixel data\n",
    "img = img.astype('float32')\n",
    "img = img / 255.0\n",
    "\n",
    "result = model.predict_classes(img)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
